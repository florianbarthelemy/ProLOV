So far, Linked Data principles and practices are being adopted by an increasing number of data providers, getting as result a global data space on the Web containing hundreds of LOD datasets \cite{Heath_Bizer_2011}. There are already several guidelines for generating, publishing, interlinking, and consuming Linked Data \cite{}. An important task, within the generation process, is to build the vocabulary to be used for modelling the domain of the data sources, and the common recommendation is to reuse as much as possible available vocabularies \cite{}. This reuse approach speeds up the vocabulary development, and therefore, publishers will save time, efforts, and resources. 

At the time of writing we have not found specific and detailed guidelines that describe how to reuse available vocabularies when building vocabularies. There are research efforts, like the NeOn Methodology \cite{}, and the W3C Working Group Note \cite{}, but they do not provide guidelines on how to reuse vocabularies at low fine grained, i.e., reusing specific classes and properties. Our claim is that this difficulty in how to reuse vocabularies at low fine grained is one of major barriers to the vocabulary development and in consequence to deployment of Linked Data.

Moreover, the recent success of Linked Open Vocabularies (LOV\footnote{\url{http://lov.okfn.org/dataset/lov/}}) as a central point for curated catalog of ontologies is helping to convey on best practices to publish vocabularies on the Web, as well as to help in the Data publication activity on the Web. LOV comes with many features, such as an API, a search function and a SPARQL endpoint.

In this paper we propose an initial set of guidelines for this task, and provide technological support by means of a plugin for \protege, which is one the popular framework for developing ontologies in a variety of formats including OWL, RDF(S), and XML Schema. It is backed by a strong community of developers and users in many domains. One success on \protege also lies on the availability to extend the core framework adding new functionalities by means of plug-ins. In addition, we propose to explore, design and implement a plug-in of LOV in \protege for easing the development of ontologies by reusing existing vocabularies at low fine grained level. The tool has to improve the modeling and reuse of ontologies used in the LOD cloud

%, by providing the following features in Prot{\'e}g{\'e}:
%\begin{itemize}
%\item Import easily vocabularies from LOV into \protege. 
%\item Propose to the user a list of candidate vocabularies in LOV matching the term
%\item Have an updating mechanism (synchronization) to LOV catalog
%\item Check if a new vocabulary created in \protege satisfied the LOV recommendations \cite{pybernard12}
%\item Suggest to LOV a new created vocabulary within \protege.
%\end{itemize}

%This paper presents \protege, a first implementation of the LOV realized as a plugin for the ontology editor \protege. 
 
\section{Reusing vocabularies when building ontologies}
In this section we describe the procedure of reusing available vocabulares when building ontologies. In a nutshell, the activity of building vocabularies by reusing available vocabularies consits of
\begin{itemize}
	\item Search for suitable vocabularies to reuse. As we aforementioned, LOV is the current reference for vocabularies in the LOD cloud. We conduct this search using the terms of the application domain. 
	\item Once we have selected the particular term, of a particular vocabulary, we have to reuse the term that we need from external ontologies, but do not explicitly import it. In this case we do not benefit from the axioms of the external ontology unless we copy the relevant axioms too. But we benefit from the fact that we are reusing existing terms that are possible well known. We have three alternatives here
	\begin{enumerate}
		\item Include the term in our current ontology and include the \emph{owl:equivalentClass}/\emph{owl:equivalentProperty} axiom with the local term.
		\item Include the term in our current ontology and include the \emph{rdfs:subClassOf}/\emph{rdfs:subPropertyOf} axiom with the local term.
		\item Reuse the term directly in the local ontology, i.e., include all the axioms related of the current term.
	\end{enumerate}
		We can combine all the approaches. The approach we choose in each case can be based on reasoning issues (expressiveness, size, conformance to DL, modularity), querying issues, robustness, linkage, reusability, taste, belief, mood, magnetic field, humour, weather, topology, spirituality, life, etc.
\end{itemize}
